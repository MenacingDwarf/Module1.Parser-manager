{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9616d08",
   "metadata": {},
   "source": [
    "# Import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4367adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "from user_agent import generate_user_agent\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6819b47",
   "metadata": {},
   "source": [
    "Сбор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1adb3dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://habr.com/ru/all/'\n",
    "# main_url = 'https://habr.com'\n",
    "# headers = {'User-Agent': generate_user_agent(device_type=\"desktop\", os=('mac', 'linux'))}\n",
    "# start_page = requests.get(url, headers = headers)\n",
    "# soup = BeautifulSoup(start_page.text, 'html.parser')\n",
    "# article_list = soup.find_all('a', {'class': 'tm-article-snippet__title-link'})\n",
    "# %%time\n",
    "# for article in article_list:\n",
    "#     movie_link = article.get('href')\n",
    "#     name = movie_link.split('/')[-2]\n",
    "#     ritem = requests.get(main_url + movie_link, headers = headers)\n",
    "#     with open('articles/' + name + '.html', 'w', encoding='utf-8') as output_file:\n",
    "#         output_file.write(ritem.text)\n",
    "#     time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c03727",
   "metadata": {},
   "source": [
    "Преобразование в текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbfb01cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_extract(path):\n",
    "    with open(path, 'r', encoding='utf-8') as input_file:\n",
    "        text = input_file.read()\n",
    "    isoup = BeautifulSoup(text)\n",
    "    tlist = []\n",
    "    def info_extract_helper(inlist, count = 0):\n",
    "        if(isinstance(inlist, list)):\n",
    "            for q in inlist:\n",
    "                if(isinstance(q, Tag)):\n",
    "                    if not (str(q).startswith('<script') or str(q).startswith('<style')):\n",
    "                        info_extract_helper(q.contents, count + 1)\n",
    "                else:\n",
    "                    extracted_str = q.strip()\n",
    "                    if(extracted_str and (count > 1)):\n",
    "                        tlist.append(extracted_str)\n",
    "    info_extract_helper([isoup])\n",
    "    return '\\n'.join(tlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6b049f",
   "metadata": {},
   "source": [
    "# Import PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ad2d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import pdfminer\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "# Perform layout analysis for all text\n",
    "laparams = pdfminer.layout.LAParams()\n",
    "setattr(laparams, 'all_texts', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62e1fd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    resource_manager = PDFResourceManager()\n",
    "    fake_file_handle = io.StringIO()\n",
    "    converter = TextConverter(resource_manager, fake_file_handle, laparams=laparams)\n",
    "    page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "\n",
    "    with open(pdf_path, 'rb') as fh:\n",
    "        for page in PDFPage.get_pages(fh, \n",
    "                                      caching=True,\n",
    "                                      check_extractable=True):\n",
    "            page_interpreter.process_page(page)\n",
    "\n",
    "        text = fake_file_handle.getvalue()\n",
    "\n",
    "    # close open handles\n",
    "    converter.close()\n",
    "    fake_file_handle.close()\n",
    "\n",
    "    if text:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2280359b",
   "metadata": {},
   "source": [
    "# Import Docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed68486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982b5a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_docx(docx_path):\n",
    "    doc = docx.Document(docx_path) \n",
    "    text_l = []\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text_l.append(paragraph.text)\n",
    "    return '\\n'.join(text_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60446b5c",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff7825d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(path):\n",
    "    if path.endswith('.html'):\n",
    "        text = info_extract(path)\n",
    "    elif path.endswith('.pdf'):\n",
    "        text = extract_text_from_pdf(path)\n",
    "    elif path.endswith('.docx'):\n",
    "        text = extract_text_from_docx(path)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90f0007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_t = get_text('pdf_1.pdf')\n",
    "html_t = get_text('articles/576194.html')\n",
    "docx_t = get_text('docx_1.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3641090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploiting Machine Learning to Subvert Your Spam Filter\n",
      "\n",
      "Blaine Nelson\n",
      "\n",
      "Benjamin I. P. Rubinstein\n",
      "\n",
      "Marco Barreno\n",
      "\n",
      "Fuching Jack Chi\n",
      "Charles Sutton\n",
      "University of California, Berkeley\n",
      "\n",
      "Udam Saini\n",
      "\n",
      "Anthony D. Joseph\n",
      "J. D. Tygar\n",
      "\n",
      "Kai Xia\n",
      "\n",
      "Abstract\n",
      "\n",
      "Using statistical machine learning for making security\n",
      "decisions introduces new vulnerabilities in large scale\n",
      "systems. This paper shows how an adversary can exploit\n",
      "statistical machine learning, as used in the SpamBayes\n",
      "spam ﬁlter, to render it useless—even if the adversary’s\n",
      "access is limited to only 1% of the training messages.\n",
      "We further demonstrate a new class of focused attacks\n",
      "that successfully prevent victims from receiving speciﬁc\n",
      "email messages. Finally, we introduce two new types of\n",
      "defenses against these attacks.\n",
      "\n",
      "1 Introduction\n",
      "\n",
      "This paper demonstrates how attackers can exploit ma-\n",
      "chine learning to subvert spam ﬁlters. Our attack strate-\n",
      "gies exhibit two key differences from previous work: tra-\n",
      "ditional attacks modify spam emails to evade a spam ﬁl-\n",
      "ter, whereas our attacks interfere with the training pro-\n",
      "cess of the learning algorithm and modify the ﬁlter itself ;\n",
      "and rather than focus only on placing spam emails in the\n",
      "victim’s inbox, we subvert the spam ﬁlter to remove le-\n",
      "gitimate emails from the inbox. In this paper, we explore\n",
      "the implications of the contamination assumption:\n",
      "the\n",
      "adversary can control some of the user’s training data.\n",
      "\n",
      "An attacker may have one of two goals: expose the\n",
      "victim to an advertisement or prevent the victim from\n",
      "seeing a legitimate message. Potential revenue gain for\n",
      "a spammer drives the ﬁrst goal, while the second goal\n",
      "is motivated, for example, by an organization competing\n",
      "for a contract that wants to prevent competing bids from\n",
      "reaching their intended recipient.\n",
      "\n",
      "An attacker may have detailed knowledge of a speciﬁc\n",
      "email the victim is likely to receive in the future, or the\n",
      "attacker may know particular words or general informa-\n",
      "tion about the victim’s word distribution. In many cases,\n",
      "the attacker may know nothing beyond which language\n",
      "the emails are likely to use.\n",
      "\n",
      "When an attacker wants the victim to see spam emails,\n",
      "a broad dictionary attack can render the spam ﬁlter unus-\n",
      "able, causing the victim to disable the ﬁlter (Section 3.2).\n",
      "With more information about the email distribution, the\n",
      "attacker can select a smaller dictionary of high-value fea-\n",
      "tures that are still effective. When an attacker wants to\n",
      "prevent a victim from seeing particular emails and has\n",
      "some information about those emails, the attacker can\n",
      "target them with a focused attack (Section 3.3).\n",
      "\n",
      "We demonstrate the potency of these attacks and then\n",
      "present two defenses. The Reject On Negative Impact\n",
      "(RONI) defense tests the impact of each email on train-\n",
      "ing and doesn’t train on messages that have a large nega-\n",
      "tive impact. The dynamic threshold defense dynamically\n",
      "sets the spam ﬁlter’s classiﬁcation thresholds based on\n",
      "the data rather than using SpamBayes’ static choice of\n",
      "thresholds. We show that both defenses are effective in\n",
      "preventing some attacks from succeeding.\n",
      "\n",
      "We focus on the learning algorithm underlying several\n",
      "spam ﬁlters, including SpamBayes (spambayes.source-\n",
      "forge.net), BogoFilter (bogoﬁlter.sourceforge.net), and\n",
      "the machine learning component of SpamAssassin\n",
      "(spamassassin.apache.org).1 We target SpamBayes be-\n",
      "cause it uses a pure machine learning method, it is fa-\n",
      "miliar to the academic community [14], and it is popular\n",
      "with over 700,000 downloads. Although we speciﬁcally\n",
      "attack SpamBayes, the widespread use of its statistical\n",
      "learning algorithm suggests that other ﬁlters may also be\n",
      "vulnerable to similar attacks. However, some ﬁlters, such\n",
      "as SpamAssassin, use the learner only as one component\n",
      "of a broader ﬁltering strategy.\n",
      "\n",
      "Our experimental results conﬁrm that this class of at-\n",
      "tacks presents a serious concern for statistical spam ﬁl-\n",
      "ters. A dictionary attack can make a spam ﬁlter unusable\n",
      "when controlling just 1% of the messages in the training\n",
      "set, and a well-informed focused attack can remove the\n",
      "target email from the victim’s inbox 90% of the time. Of\n",
      "\n",
      "1The primary difference between the learning elements of these\n",
      "\n",
      "three ﬁlters is in their tokenization methods.\n",
      "\n",
      "In Proceedings of First USENIX Workshop on Large Scale Exploits and Emergent Threats, April 2008\n",
      "\n",
      "\f",
      "our two defenses, one signiﬁcantly mitigates the effect of\n",
      "the dictionary attack and the other provides insight into\n",
      "the strengths and limitations of threshold-based defenses.\n",
      "\n",
      "2 Background\n",
      "\n",
      "2.1 Training model\n",
      "\n",
      "SpamBayes produces a classiﬁer from labeled examples\n",
      "to label future emails. The labels are spam (bad, unso-\n",
      "licited email), ham (good, legitimate email), and unsure\n",
      "(SpamBayes isn’t conﬁdent one way or the other). The\n",
      "classiﬁer learns from a labeled training set of ham and\n",
      "spam emails.\n",
      "\n",
      "Email clients use these labels in different ways—\n",
      "some clients ﬁlter email labeled as spam and unsure into\n",
      "“Spam-High” and “Spam-Low” folders, respectively,\n",
      "while other clients only ﬁlter email labeled as spam into\n",
      "a separate folder. Since the typical user reads most or\n",
      "all email in their inbox and rarely (if ever) looks at the\n",
      "spam/spam-high folder, the unsure labels can be prob-\n",
      "lematic. If unsure messages are ﬁltered into a separate\n",
      "folder, users may periodically read the messages in that\n",
      "folder to avoid missing important email. If instead un-\n",
      "sure messages are not ﬁltered, then the user faces those\n",
      "messages when checking the email in their inbox. Too\n",
      "much unsure email is almost as troublesome as too many\n",
      "false positives (ham labeled as spam) or false negatives\n",
      "(spam labeled as ham). In the extreme, if everything is\n",
      "labeled unsure then the user obtains no time savings at\n",
      "all from the ﬁlter.\n",
      "\n",
      "In our scenarios, an organization uses SpamBayes to\n",
      "ﬁlter multiple users’ incoming email2 and trains on ev-\n",
      "eryone’s received email. SpamBayes may also be used\n",
      "as a personal email ﬁlter, in which case the presented at-\n",
      "tacks and defenses are likely to be equally effective.\n",
      "\n",
      "To keep up with changing trends in the statistical char-\n",
      "acteristics of both legitimate and spam email, we as-\n",
      "sume that the organization retrains SpamBayes period-\n",
      "ically (e.g., weekly). Our attacks are not limited to any\n",
      "particular retraining process; they only require that the\n",
      "attacker can introduce attack data into the training set\n",
      "somehow (the contamination assumption).\n",
      "\n",
      "2.2 The contamination assumption\n",
      "\n",
      "We assume that the attacker can send emails that the\n",
      "victim will use for training—the contamination assump-\n",
      "tion—but incorporate two signiﬁcant restrictions: attack-\n",
      "ers may specify arbitrary email bodies but not headers,\n",
      "and attack emails are always trained as spam and not\n",
      "\n",
      "ham. We examine the implications of the contamination\n",
      "assumption in the remainder of this paper.\n",
      "\n",
      "How can an attacker contaminate the training set?\n",
      "Consider the following alternatives. If the victim period-\n",
      "ically retrains on all email, any email the attacker sends\n",
      "will be used for training. If the victim manually labels a\n",
      "training set, the attack emails will be included as spam\n",
      "because they genuinely are spam. Even if the victim re-\n",
      "trains only on mistakes made by the ﬁlter, the attacker\n",
      "may be able to design emails that both perform our at-\n",
      "tacks and are also misclassiﬁed by the victim’s current\n",
      "ﬁlter. We do not address the possibility that a user might\n",
      "inspect training data to remove attack emails; our attacks\n",
      "could be adjusted to evade detection strategies such as\n",
      "email size or word distributions, but we avoid pursuing\n",
      "this arms race here.\n",
      "\n",
      "Our focus on spam-labeled attack emails should be\n",
      "viewed as a restriction and not a necessary condition\n",
      "for the success of the attacks—using ham-labeled attack\n",
      "emails could enable more powerful attacks that place\n",
      "spam in a user’s inbox.\n",
      "\n",
      "2.3 SpamBayes learning method\n",
      "\n",
      "SpamBayes classiﬁes using token scores based on a sim-\n",
      "ple model of spam status proposed by Robinson [14, 17],\n",
      "based on ideas by Graham [7] together with Fisher’s\n",
      "method for combining independent signiﬁcance tests [6].\n",
      "\n",
      "SpamBayes tokenizes the header and body of each\n",
      "email before constructing token spam scores. Robinson’s\n",
      "method assumes that the presence or absence of tokens\n",
      "in an email affect its spam status independently. For each\n",
      "token w, the raw token spam score\n",
      "\n",
      "PS(w) =\n",
      "\n",
      "NH NS(w)\n",
      "NH NS(w) + NSNH (w)\n",
      "\n",
      "(1)\n",
      "\n",
      "is computed from the counts NS, NH , NS(w), and\n",
      "NH (w)—the number of spam emails, ham emails, spam\n",
      "emails that include w and ham emails that include w.\n",
      "\n",
      "Robinson smooths PS(w) through a convex combina-\n",
      "tion with a prior belief x, weighting the quantities by\n",
      "N (w) (the number of training emails with w) and s (cho-\n",
      "sen for strength of prior), respectively:\n",
      "\n",
      "f (w) =\n",
      "\n",
      "s\n",
      "s + N (w)\n",
      "\n",
      "x +\n",
      "\n",
      "N (w)\n",
      "s + N (w)\n",
      "\n",
      "PS(w) . (2)\n",
      "\n",
      "2We use the terms user and victim interchangeably for either orga-\n",
      "\n",
      "nization or individual; the meaning will be clear from context.\n",
      "\n",
      "For a new message E, Robinson uses Fisher’s method\n",
      "to combine the spam scores of the most signiﬁcant to-\n",
      "\n",
      "\f",
      "kens3 into a message score\n",
      "\n",
      "I(E) =\n",
      "\n",
      "∈ [0, 1] ,\n",
      "\n",
      "(3)\n",
      "\n",
      "1 + H(E) − S(E)\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "H(E) = 1 − χ2\n",
      "2n\n",
      "\n",
      "−2\n",
      "\n",
      "log f (w)\n",
      "\n",
      " , (4)\n",
      "\n",
      "(cid:88)\n",
      "\n",
      "w∈δ(E)\n",
      "\n",
      "where χ2\n",
      "2n (·) denotes the cumulative distribution func-\n",
      "tion of the chi-square distribution with 2n degrees of\n",
      "freedom. S(E) is deﬁned like H(E) but with f (w) re-\n",
      "placed by 1 − f (w). SpamBayes predicts by threshold-\n",
      "ing against two user-tunable thresholds θ0 and θ1, with\n",
      "defaults θ0 = 0.15 and θ1 = 0.9: SpamBayes predicts\n",
      "ham, unsure, or spam if I falls into the interval [0, θ0],\n",
      "(θ0, θ1], or (θ1, 1], respectively.\n",
      "\n",
      "The inclusion of an unsure category spam and ham\n",
      "prevents us from purely using misclassiﬁcation rates\n",
      "(false positives and false negatives) for evaluation. We\n",
      "must also consider spam-as-unsure and ham-as-unsure\n",
      "emails. Because of the considerations in Section 2.1, un-\n",
      "sure misclassiﬁcations of ham emails are nearly as bad\n",
      "for the user as false positives.\n",
      "\n",
      "3 Attacks\n",
      "\n",
      "3.1 Attack framework\n",
      "\n",
      "In a previous paper, we categorize attacks against ma-\n",
      "chine learning systems along three axes [1]. For con-\n",
      "creteness, we will describe the taxonomy in the context\n",
      "of spam ﬁltering, but it applies readily to other security\n",
      "applications. The axes of the taxonomy are:\n",
      "\n",
      "Inﬂuence:\n",
      "Security violation:\n",
      "Speciﬁcity:\n",
      "\n",
      "Causative or Exploratory\n",
      "Integrity or Availability\n",
      "Targeted or Indiscriminate\n",
      "\n",
      "The ﬁrst axis of the taxonomy describes the capability\n",
      "of the attacker: whether (a) the attacker has the ability\n",
      "to inﬂuence the training data that is used to construct the\n",
      "classiﬁer (a Causative attack) or (b) the attacker does not\n",
      "inﬂuence the learned classiﬁer, but can send new emails\n",
      "to the classiﬁer, and observe its decisions on these care-\n",
      "fully crafted emails (an Exploratory attack).\n",
      "\n",
      "The second axis indicates the type of security viola-\n",
      "tion caused: (a) to create false negatives, in which spam\n",
      "messages slip through the ﬁlter (an Integrity violation);\n",
      "or (b) to create false positives, in which ham messages\n",
      "are incorrectly ﬁltered (an Availability violation).\n",
      "\n",
      "The third axis refers to how speciﬁc the attacker’s in-\n",
      "tention is: whether (a) the attack is Targeted to degrade\n",
      "\n",
      "3SpamBayes uses at most 150 tokens from E with scores furthest\n",
      "\n",
      "from 0.5 and outside the interval [0.4, 0.6]. We call this set δ(E).\n",
      "\n",
      "the classiﬁer’s performance on one particular type of\n",
      "email or (b) the attack aims to cause the classiﬁer to fail\n",
      "in an Indiscriminate fashion on a broad class of email.\n",
      "\n",
      "Our focus is on Causative Availability attacks, which\n",
      "manipulate the ﬁlter’s training data to increase false pos-\n",
      "itives. We consider both Indiscriminate and Targeted at-\n",
      "tacks. In Indiscriminate attacks, enough false positives\n",
      "force the victim to disable the spam ﬁlter, or at least fre-\n",
      "quently search through spam/unsure folders to ﬁnd legiti-\n",
      "mate messages that were ﬁltered away. In either case, the\n",
      "victim is forced to view more spam. In Targeted attacks,\n",
      "the attacker does not disable the ﬁlter but surreptitiously\n",
      "prevents the victim from receiving certain types of email.\n",
      "For example, a company may wish to prevent its com-\n",
      "petitors from receiving email about a bidding process in\n",
      "which they are all competing.\n",
      "\n",
      "3.2 Dictionary attacks\n",
      "\n",
      "Our ﬁrst attack is an Indiscriminate attack. The idea is\n",
      "to send attack emails that contain many words likely\n",
      "to occur in legitimate email. When the victim trains\n",
      "SpamBayes with these attack emails marked as spam, the\n",
      "words in the attack emails will have higher spam score.\n",
      "Future legitimate email is more likely to be marked as\n",
      "spam if it contains words from the attack email.\n",
      "\n",
      "When the attacker lacks knowledge about the victim’s\n",
      "email, one simple attack is to include an entire dictio-\n",
      "nary of the English language. This technique is the basic\n",
      "dictionary attack. We use the GNU aspell English\n",
      "dictionary version 6.0-0, containing 98,568 words.\n",
      "\n",
      "A further reﬁnement uses a word source with distri-\n",
      "bution closer to the victim’s email distribution. For ex-\n",
      "ample, a large pool of Usenet newsgroup postings may\n",
      "have colloquialisms, misspellings, and other “words” not\n",
      "found in a dictionary; furthermore, using the most fre-\n",
      "quent words in such a corpus may allow the attacker to\n",
      "send smaller emails without losing much effectiveness.\n",
      "\n",
      "3.3 Focused attack\n",
      "\n",
      "Our second attack—the focused attack—assumes knowl-\n",
      "edge of a speciﬁc legitimate email or type of email the at-\n",
      "tacker wants blocked by the victim’s spam ﬁlter. This is\n",
      "a Causative Targeted Availability attack. In the focused\n",
      "attack, the attacker sends attack emails to the victim con-\n",
      "taining words likely to occur in the target email. When\n",
      "SpamBayes trains on this attack email, the spam scores\n",
      "of the targeted tokens increase, so the target message is\n",
      "more likely to be ﬁltered as spam. For example, consider\n",
      "a malicious contractor wishing to prevent the victim from\n",
      "receiving messages with competing bids. The attacker\n",
      "sends spam emails to the victim with words such as the\n",
      "names of competing companies, their products, and their\n",
      "\n",
      "\f",
      "Parameter\n",
      "Training set size\n",
      "Test set size\n",
      "Spam prevalence\n",
      "Attack fraction\n",
      "\n",
      "Folds of validation\n",
      "Target Emails\n",
      "\n",
      "Dictionary Attack\n",
      "2,000, 10,000\n",
      "200, 1,000\n",
      "0.50, 0.75\n",
      "0.001,\n",
      "0.005,\n",
      "0.02, 0.05, 0.10\n",
      "10\n",
      "N/A\n",
      "\n",
      "0.01,\n",
      "\n",
      "Focused Attack\n",
      "5,000\n",
      "N/A\n",
      "0.50\n",
      "0.02 to 0.50 increment-\n",
      "ing by 0.02\n",
      "5 repetitions\n",
      "20\n",
      "\n",
      "RONI Defense\n",
      "20\n",
      "50\n",
      "0.50\n",
      "0.05\n",
      "\n",
      "5 repetitions\n",
      "N/A\n",
      "\n",
      "Threshold Defense\n",
      "2,000, 10,000\n",
      "200, 1,000\n",
      "0.50\n",
      "0.001, 0.01, 0.05, 0.10\n",
      "\n",
      "5\n",
      "N/A\n",
      "\n",
      "Table 1: Parameters used in our experiments.\n",
      "\n",
      "employees. The bid messages may even follow a com-\n",
      "mon template, making the attack easier to craft.\n",
      "\n",
      "The attacker may have different levels of knowledge\n",
      "about the target email. In the extreme case, the attacker\n",
      "might know the exact content of the target email and\n",
      "use all of its words. More realistically, the attacker only\n",
      "guesses a fraction of the email’s content. In either case,\n",
      "the attack email may include additional words as well.\n",
      "\n",
      "The focused attack is more concise than the dictionary\n",
      "attack because the attacker has detailed knowledge of the\n",
      "target and need not affect other messages.\n",
      "\n",
      "3.4 Optimal attack function\n",
      "\n",
      "The dictionary and focused attacks can be seen as two\n",
      "instances of a common attack in which the attacker has\n",
      "different amounts of knowledge about the victim’s email.\n",
      "Without loss of generality, suppose the attacker generates\n",
      "only a single attack message a. The victim adds it to the\n",
      "training set, trains, and classiﬁes a new message m. Both\n",
      "a and m are indicator vectors, where the ith component is\n",
      "true if word i appears in the email. The attacker also has\n",
      "some (perhaps limited) knowledge of the next email the\n",
      "victim will receive. This knowledge can be represented\n",
      "as a distribution p—the vector of probabilities that each\n",
      "word appears in the next message.\n",
      "\n",
      "The goal of the attacker is to choose an attack email a\n",
      "that maximizes the expected spam score Ia (Equation 3\n",
      "with the attack message a in the spam training set) of the\n",
      "next legitimate email m drawn from distribution p; that\n",
      "is, maxa Em∼p [Ia(m)] . In order to describe the optimal\n",
      "attacks under this criterion, we make two observations.\n",
      "First, the spam scores of distinct words do not interact;\n",
      "that is, adding a word w to the attack does not change the\n",
      "score f (u) of some different word u (cid:54)= w. Second, it can\n",
      "be shown that I is monotonically non-decreasing in each\n",
      "f (w). Therefore the best way to increase Ia is to include\n",
      "additional words in the attack message.\n",
      "\n",
      "Now let us consider speciﬁc choices for the next\n",
      "email’s distribution p. First, if the attacker has little\n",
      "knowledge about the words in target emails, we model\n",
      "this by setting p to be uniform over all vectors m rep-\n",
      "\n",
      "resenting emails. We can optimize the expected spam\n",
      "score by including all possible words in the attack email.\n",
      "This optimal attack is infeasible in practice but can be\n",
      "simulated: one approximation includes all words in the\n",
      "victim’s primary language, such as an English dictionary.\n",
      "This yields the dictionary attack.\n",
      "\n",
      "Second, if the attacker has speciﬁc knowledge of a tar-\n",
      "get email, we can represent this by setting pi to 1 if and\n",
      "only if the ith word is in the target email. The optimal at-\n",
      "tack still maximizes the expected spam score, but a more\n",
      "compact attack that is also optimal is to include all of the\n",
      "words in the target email. This is the focused attack.\n",
      "\n",
      "The attacker’s knowledge usually falls between these\n",
      "extremes. For example, the attacker may use information\n",
      "about the distribution of words in English text to make\n",
      "the attack more efﬁcient, such as characteristic vocabu-\n",
      "lary or jargon typical of the victim. Either of these results\n",
      "in a distribution p over words in the victim’s email. From\n",
      "this it should be possible to derive an optimal constrained\n",
      "attack, but we leave this to future work.\n",
      "\n",
      "4 Experiments\n",
      "\n",
      "4.1 Experimental method\n",
      "\n",
      "In our experiments we use the Text Retrieval Confer-\n",
      "ence (TREC) 2005 spam corpus [4], which is based on\n",
      "the Enron email corpus [11] and contains 92,189 emails\n",
      "(52,790 spam and 39,399 ham). This corpus has sev-\n",
      "eral strengths: it comes from a real-world source, it has\n",
      "a large number of emails, and its creators took care that\n",
      "the added spam does not have obvious artifacts to dif-\n",
      "ferentiate it. We also use a corpus constructed from a\n",
      "subset of Usenet English postings to generate words for\n",
      "our attacks [18].\n",
      "\n",
      "We restrict the attacker to have limited control over\n",
      "the headers of attack emails. We implement this assump-\n",
      "tion either by using the entire header from a randomly\n",
      "selected spam email from TREC (focused attack) or by\n",
      "using an empty header (all other attacks).\n",
      "\n",
      "We measure the effect of each attack by comparing\n",
      "classiﬁcation performance of the control and compro-\n",
      "\n",
      "\f",
      "mised ﬁlters using K-fold cross-validation (or K repe-\n",
      "titions with new random dataset samples in the case of\n",
      "the focused attack). In cross-validation, we partition the\n",
      "dataset into K subsets and perform K train-test epochs.\n",
      "During the ith epoch, the ith subset is set aside as a test\n",
      "set and the remaining (K − 1) subsets are used for train-\n",
      "ing. Each email from our original dataset serves inde-\n",
      "pendently as both training and test data.\n",
      "\n",
      "In the following sections, we show the effect of our\n",
      "attacks on test sets of held-out messages. Because our\n",
      "attacks are designed to cause ham to be misclassiﬁed,\n",
      "we only show their effect on ham messages; their effect\n",
      "on spam is marginal. Our graphs do not include error\n",
      "bars since we observed that the variation on our tests was\n",
      "small. See Table 1 for our experimental parameters.\n",
      "\n",
      "4.2 Dictionary attack results\n",
      "\n",
      "We examined dictionary attacks as a function of the\n",
      "percent of attack messages in the training set (see Fig-\n",
      "It shows the misclassiﬁcation rates of three\n",
      "ure 1).\n",
      "dictionary attack variants averaging over ten-fold cross-\n",
      "validation. The optimal attack quickly causes the ﬁlter\n",
      "to label all ham emails as spam. The Usenet dictionary\n",
      "attack (90,000 top ranked words from the Usenet corpus)\n",
      "causes signiﬁcantly more ham emails to be misclassiﬁed\n",
      "than the Aspell dictionary attack, since it contains com-\n",
      "mon misspellings and slang terms that are not present in\n",
      "the Aspell dictionary (the overlap between the Aspell and\n",
      "Usenet dictionaries is around 61,000 words). These vari-\n",
      "ations of the attack require relatively few attack emails to\n",
      "signiﬁcantly degrade the SpamBayes accuracy. By 101\n",
      "attack emails (1% of 10,000), the accuracy falls signiﬁ-\n",
      "cantly for each attack variation; at this point most users\n",
      "will gain no advantage from continued use of the ﬁlter.\n",
      "\n",
      "To be fair, although the attack emails make up a small\n",
      "percentage of the number of messages in a poisoned in-\n",
      "box, they make up a large percentage of the number of\n",
      "tokens. For example, at 204 attack emails (2% of the\n",
      "messages), the Usenet attack includes approximately 6.4\n",
      "times as many tokens as the original dataset and the As-\n",
      "pell attack includes 7 times. An attack with fewer tokens\n",
      "likely would be harder to detect; however, the number\n",
      "of messages is a more visible feature.\n",
      "It is of signiﬁ-\n",
      "cant interest that so few attack messages can degrade a\n",
      "widely-deployed ﬁltering algorithm to such a degree.\n",
      "\n",
      "4.3 Focused attack results\n",
      "\n",
      "We run each repetition of the focused attack as follows.\n",
      "First we randomly select a ham email from the TREC\n",
      "corpus to serve as the target of the attack. We use a clean,\n",
      "non-malicious 5,000-message inbox with 50% spam. We\n",
      "\n",
      "Figure 1: Three dictionary attacks on initial training set\n",
      "of 10,000 messages (50% spam). We plot percent of ham\n",
      "classiﬁed as spam (dashed lines) and as spam or unsure\n",
      "(solid lines) against the attack as percent of the training\n",
      "set. We show the optimal attack (black (cid:52)), the Usenet\n",
      "dictionary attack (blue (cid:3)), and the Aspell dictionary at-\n",
      "tack (green (cid:13)). Each attack renders the ﬁlter unusable\n",
      "with as little as 1% control (101 messages).\n",
      "\n",
      "Figure 2: Effect of the targeted attack as a function of the\n",
      "probability of guessing target tokens. Each bar depicts\n",
      "the fraction of target emails classiﬁed as spam, ham, and\n",
      "unsure after the attack. The initial inbox contains 5,000\n",
      "emails (50% spam).\n",
      "\n",
      "Optimal\n",
      "\n",
      "Usenet\n",
      "\n",
      "Dictionary\n",
      "\n",
      " \n",
      "\n",
      "100\n",
      "\n",
      "90\n",
      "\n",
      "80\n",
      "\n",
      "70\n",
      "\n",
      "60\n",
      "\n",
      "50\n",
      "\n",
      "40\n",
      "\n",
      "30\n",
      "\n",
      "20\n",
      "\n",
      "10\n",
      "\n",
      "d\n",
      "e\n",
      "\n",
      "l\n",
      "\n",
      "i\n",
      "f\n",
      "i\n",
      "s\n",
      "s\n",
      "a\n",
      "c\n",
      "s\n",
      "M\n",
      "m\n",
      "a\n",
      "H\n",
      "\n",
      " \n",
      "\n",
      "i\n",
      "\n",
      " \n",
      "t\n",
      "s\n",
      "e\n",
      "T\n",
      "\n",
      " \n",
      "f\n",
      "\n",
      "o\n",
      "\n",
      " \n",
      "t\n",
      "\n",
      "n\n",
      "e\n",
      "c\n",
      "r\n",
      "e\n",
      "P\n",
      "\n",
      "0\n",
      " \n",
      "0\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "5\n",
      "Percent Control of Training Set\n",
      "\n",
      "4\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "8\n",
      "\n",
      "9\n",
      "\n",
      "10\n",
      "\n",
      "s\n",
      "s\n",
      "e\n",
      "c\n",
      "c\n",
      "u\n",
      "s\n",
      " \n",
      "k\n",
      "c\n",
      "a\n",
      "t\n",
      "t\n",
      "a\n",
      " \n",
      "f\n",
      "o\n",
      " \n",
      "e\n",
      "g\n",
      "a\n",
      "t\n",
      "n\n",
      "e\n",
      "c\n",
      "r\n",
      "e\n",
      "P\n",
      "\n",
      "0\n",
      "0\n",
      "1\n",
      "\n",
      "0\n",
      "8\n",
      "\n",
      "0\n",
      "6\n",
      "\n",
      "0\n",
      "4\n",
      "\n",
      "0\n",
      "2\n",
      "\n",
      "0\n",
      "\n",
      "ham\n",
      "\n",
      "unsure\n",
      "\n",
      "spam\n",
      "\n",
      "0 1\n",
      "\n",
      "0 3\n",
      "\n",
      "0 5\n",
      "\n",
      "0 9\n",
      "\n",
      "Probability of guessing target tokens\n",
      "\n",
      "\f",
      "graph represents the before/after score of a token; any\n",
      "point above the line y = x increased due to the attack\n",
      "and any point below is a decrease. From these graphs it is\n",
      "clear that tokens included in the attack typically increase\n",
      "signiﬁcantly while those not included decrease slightly.\n",
      "Since the increase in score is more signiﬁcant for in-\n",
      "cluded tokens than the decrease in score for excluded\n",
      "tokens, the attack has substantial impact even when the\n",
      "attacker has a low probability of guessing tokens as seen\n",
      "in Figure 2. Further, the before/after histograms in Fig-\n",
      "ure 4 provide a direct indicator of the attack’s success.\n",
      "\n",
      "5 Defenses\n",
      "\n",
      "5.1 RONI defense\n",
      "\n",
      "Our Causative attacks work because training on attack\n",
      "emails causes the ﬁlter to learn incorrectly and misclas-\n",
      "sify emails. Each attack email contributes towards the\n",
      "degradation of the ﬁlter’s performance; if we can mea-\n",
      "sure each email’s impact, then we can remove deleterious\n",
      "messages from the training set.\n",
      "\n",
      "In the Reject On Negative Impact (RONI) defense, we\n",
      "measure the incremental effect of each query email Q by\n",
      "testing the performance difference with and without that\n",
      "email. We independently sample a 20-message training\n",
      "set T and a 50-message validation set V ﬁve times from\n",
      "the initial pool of emails given to SpamBayes for train-\n",
      "ing. We train on both T and T ∪ {Q} and measure the\n",
      "impact of each query email as the average change in in-\n",
      "correct classiﬁcations on V over the ﬁve trials. We elim-\n",
      "inate Q from training if the impact is signiﬁcantly nega-\n",
      "tive. We test with 120 random non-attack spam messages\n",
      "and 15 repetitions each of seven variants of the dictionary\n",
      "attacks in Section 3.2.\n",
      "\n",
      "Preliminary experiments show that\n",
      "\n",
      "the RONI de-\n",
      "fense is extremely successful against dictionary attacks,\n",
      "identifying 100% of the attack emails without ﬂagging\n",
      "any non-attack emails. Each dictionary attack message\n",
      "causes at least an average decrease of 6.8 ham-as-ham\n",
      "messages. In sharp contrast, non-attack spam messages\n",
      "cause at most an average decrease of 4.4 ham-as-ham\n",
      "messages. This clear region of separability means a sim-\n",
      "ple threshold on this statistic is effective at separating\n",
      "dictionary attack emails from non-attack spam.\n",
      "\n",
      "We plan to extend our initial experiments for the RONI\n",
      "defense with larger test sets along with a larger varia-\n",
      "tion in the number of attack emails. Our initial small ex-\n",
      "periment, however, gives us conﬁdence that this defense\n",
      "would work given a larger test set due to the large impact\n",
      "a small number of attack emails have on performance.\n",
      "\n",
      "However, the RONI defense fails to differentiate fo-\n",
      "cused attack emails from non-attack emails. The expla-\n",
      "the dictionary attack broadly affects\n",
      "nation is simple:\n",
      "\n",
      "Figure 3: Effect of the focused attack as a function of the\n",
      "number of attack emails with a ﬁxed probability (p=0.5)\n",
      "that the attacker guesses each token. The dashed line\n",
      "shows the percentage of target ham messages misclas-\n",
      "siﬁed as spam after the attack, and the solid line the\n",
      "percentage of targets that are misclassiﬁed as unsure or\n",
      "spam after the attack. The initial inbox contains 5,000\n",
      "emails (50% spam).\n",
      "\n",
      "repeat the entire attack procedure independently for 20\n",
      "randomly-selected target emails.\n",
      "\n",
      "In Figure 2, we examine the effectiveness of the attack\n",
      "when the attacker has increasing knowledge of the target\n",
      "email by simulating the process of the attacker guess-\n",
      "ing tokens from the target email. For this ﬁgure, there\n",
      "are 300 attack emails—16% of the original number of\n",
      "training emails. We assume that the attacker correctly\n",
      "guesses each word in the target with probability p in\n",
      "{0.1, 0.3, 0.5, 0.9}—the x-axis of Figure 2. The y-axis\n",
      "shows the proportion of the 20 targets classiﬁed as ham,\n",
      "unsure and spam. As expected, the attack is increasingly\n",
      "effective as p increases. If the attacker guesses only 30%\n",
      "of the tokens in the target, classiﬁcation changes on 60%\n",
      "of the target emails.\n",
      "\n",
      "In Figure 3, we examine the attack’s effect on misclas-\n",
      "siﬁcations of the targeted emails as the number of attack\n",
      "messages increases. In this ﬁgure, we ﬁx the probabil-\n",
      "ity of guessing each target token at 0.5. The x-axis is\n",
      "the number of messages in the attack and the y-axis is\n",
      "the percent of messages misclassiﬁed. With 100 attack\n",
      "emails, out of a initial mailbox size of 5,000, the target\n",
      "email is misclassiﬁed 32% of the time.\n",
      "\n",
      "We ﬁnd more insight by examining the attack’s effect\n",
      "on three representative emails (see Figure 4). Each of the\n",
      "panels in the ﬁgure represents a single target email from\n",
      "each of three attack results: ham misclassiﬁed as spam\n",
      "(Left), ham misclassiﬁed as unsure (Middle), and ham\n",
      "correctly classiﬁed as ham (Right). Each point in the\n",
      "\n",
      "100\n",
      "\n",
      "80\n",
      "\n",
      "60\n",
      "\n",
      "40\n",
      "\n",
      "20\n",
      "\n",
      "d\n",
      "e\n",
      "i\n",
      "f\n",
      "i\n",
      "s\n",
      "s\n",
      "a\n",
      "l\n",
      "c\n",
      "s\n",
      "i\n",
      "\n",
      " \n",
      "\n",
      "M\n",
      "m\n",
      "a\n",
      "H\n",
      "\n",
      " \n",
      "t\n",
      "e\n",
      "g\n",
      "r\n",
      "a\n",
      "T\n",
      " \n",
      "f\n",
      "o\n",
      "\n",
      " \n",
      "t\n",
      "n\n",
      "e\n",
      "c\n",
      "r\n",
      "e\n",
      "P\n",
      "\n",
      " \n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "2\n",
      "8\n",
      "Percent Control of Training Set\n",
      "\n",
      "6\n",
      "\n",
      "4\n",
      "\n",
      "10\n",
      "\n",
      "\f",
      "Figure 4: Effect of the focused attack on three representative emails— one graph for each target. Each point is a token\n",
      "in the email. The x-axis is the token spam score in Equation (2) before the attack (0 means ham and 1 means spam).\n",
      "The y-axis is the spam score after the attack. The red ×’s are tokens that were included in the attack and the blue\n",
      "(cid:13)’s are tokens that were not in the attack. The histograms show the distribution of spam scores before the attack (at\n",
      "bottom) and after the attack (at right).\n",
      "\n",
      "emails, including training emails, while the focused at-\n",
      "tack is targeted at a future email, so its effects may not\n",
      "be evident on the training set alone.\n",
      "\n",
      "5.2 Dynamic threshold defense\n",
      "\n",
      "Distribution-based attacks increase the spam score of\n",
      "ham email but they also tend to increase the spam score\n",
      "of spam. Thus with new θ0, θ1 thresholds, it may still\n",
      "be possible to accurately distinguish between these kinds\n",
      "of messages after an attack. Based on this hypothesis,\n",
      "we propose and test a dynamic threshold defense, which\n",
      "dynamically adjusts θ0, θ1. With an adaptive threshold\n",
      "scheme, attacks that shift all scores will not be effective\n",
      "since rankings are invariant to such shifts.\n",
      "\n",
      "To determine dynamic values of θ0 and θ1, we split\n",
      "the full training set in half. We use one half to train a\n",
      "SpamBayes ﬁlter F and the other half as a validation\n",
      "set V . Using F , we obtain a score for each email in\n",
      "V . From this information, we can pick threshold values\n",
      "that more accurately separate ham and spam emails. We\n",
      "deﬁne a utility function for choosing threshold t, g(t) =\n",
      "NS,<(t) (NS,<(t) + NH,>(t))−1, where NS,<(t) is the\n",
      "number of spam emails with scores less than t and\n",
      "NH,>(t) is the number of ham emails with scores greater\n",
      "than t. We select θ0 so that g(θ0) is 0.05 or 0.10, and we\n",
      "select θ1 so that g(θ1) is 0.95 or 0.90, respectively.\n",
      "\n",
      "This defense shows some promise against the dictio-\n",
      "nary attacks in a preliminary experiment. As shown in\n",
      "Figure 5, the misclassiﬁcation of ham emails is signif-\n",
      "icantly reduced compared to SpamBayes alone. At all\n",
      "stages of the attack, ham emails are never classiﬁed as\n",
      "\n",
      "spam and only a moderate amount of them are labeled\n",
      "as unsure. However, while ham messages are often clas-\n",
      "siﬁed properly, the dynamic threshold causes almost all\n",
      "spam messages to be classiﬁed as unsure even when the\n",
      "attack is only 1% of the inbox. This shows that the dy-\n",
      "namic threshold defense failed to adequately separate\n",
      "ham and spam given the number of spam also classi-\n",
      "ﬁed as unsure; we are exploring this defense under other\n",
      "choices of the thresholds.\n",
      "\n",
      "6 Related work\n",
      "\n",
      "Many authors have examined adversarial learning from\n",
      "a more theoretical perspective. For example, within the\n",
      "Probably Approximately Correct framework, Kearns and\n",
      "Li bound the classiﬁcation error an adversary that has\n",
      "control over a fraction β of the training set can cause [9].\n",
      "Dalvi et al. apply game theory to the classiﬁcation prob-\n",
      "lem [5]. They model interactions between the classiﬁer\n",
      "and attacker as a game and ﬁnd the optimal counter-\n",
      "strategy for the classiﬁer against an optimal opponent.\n",
      "\n",
      "In this paper we focus on Causative attacks. Most ex-\n",
      "isting attacks against content-based spam ﬁlters are Ex-\n",
      "ploratory attacks that do not inﬂuence training but engi-\n",
      "neer spam messages so they pass through the ﬁlter. For\n",
      "example, Lowd and Meek explore reverse-engineering a\n",
      "spam classiﬁer to ﬁnd high-value messages that the ﬁlter\n",
      "does not block [12, 13], Karlberger et al. study the effect\n",
      "of replacing strong spam words with synonyms [8], and\n",
      "Wittel and Wu study the effect of adding common words\n",
      "to spam to get it through a spam ﬁlter [19].\n",
      "\n",
      "Token score before attack\n",
      "\n",
      "0 0        0 2        0 4        0 6         0 8        1 0\n",
      "\n",
      "l\n",
      "l\n",
      "\n",
      "k\n",
      "c\n",
      "a\n",
      "t\n",
      "t\n",
      "a\n",
      " \n",
      "r\n",
      "e\n",
      "t\n",
      "f\n",
      "a\n",
      " \n",
      "e\n",
      "r\n",
      "o\n",
      "c\n",
      "s\n",
      " \n",
      "n\n",
      "e\n",
      "k\n",
      "o\n",
      "T\n",
      "\n",
      "0\n",
      "\n",
      "1\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "8\n",
      "\n",
      "0\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "6\n",
      "\n",
      "0\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "4\n",
      "\n",
      "0\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "2\n",
      "0\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "0\n",
      "0\n",
      "\n",
      "l\n",
      "\n",
      "l\n",
      "ll\n",
      "\n",
      "l\n",
      "\n",
      "l\n",
      "l\n",
      "\n",
      "l\n",
      "ll\n",
      "ll\n",
      "l\n",
      "l\n",
      "\n",
      "Token score before attack\n",
      "\n",
      "0 0        0 2        0 4        0 6        0 8        1 0\n",
      "\n",
      "k\n",
      "c\n",
      "a\n",
      "t\n",
      "t\n",
      "a\n",
      " \n",
      "r\n",
      "e\n",
      "t\n",
      "f\n",
      "a\n",
      " \n",
      "e\n",
      "r\n",
      "o\n",
      "c\n",
      "s\n",
      " \n",
      "n\n",
      "e\n",
      "k\n",
      "o\n",
      "T\n",
      "\n",
      "0\n",
      "\n",
      "1\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "8\n",
      "\n",
      "0\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "6\n",
      "\n",
      "0\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "4\n",
      "\n",
      "0\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "2\n",
      "\n",
      "0\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "0\n",
      "0\n",
      "\n",
      "l\n",
      "\n",
      "l\n",
      "\n",
      "l\n",
      "\n",
      "l\n",
      "\n",
      "l\n",
      "\n",
      "l\n",
      "l\n",
      "\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "\n",
      "l\n",
      "\n",
      "ll\n",
      "l\n",
      "l\n",
      "\n",
      "Token score before attack\n",
      "\n",
      "0 0\n",
      "\n",
      "0 2       0 4        0 6         0 8        1 0\n",
      "\n",
      "l\n",
      "\n",
      "l\n",
      "\n",
      "k\n",
      "c\n",
      "a\n",
      "t\n",
      "t\n",
      "a\n",
      " \n",
      "r\n",
      "e\n",
      "t\n",
      "f\n",
      "a\n",
      " \n",
      "e\n",
      "r\n",
      "o\n",
      "c\n",
      "s\n",
      " \n",
      "n\n",
      "e\n",
      "k\n",
      "o\n",
      "T\n",
      "\n",
      "0\n",
      "\n",
      "1\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "8\n",
      "\n",
      "0\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "6\n",
      "\n",
      "0\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "4\n",
      "\n",
      "0\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "2\n",
      "\n",
      "0\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "l\n",
      "\n",
      "l\n",
      "\n",
      "l\n",
      "\n",
      "l\n",
      "l\n",
      "l\n",
      "\n",
      "l\n",
      "l\n",
      "\n",
      "l\n",
      "ll\n",
      "l\n",
      "llll\n",
      "l\n",
      "lllll\n",
      "ll\n",
      "l\n",
      "l\n",
      "\n",
      "\f",
      "7 Conclusion\n",
      "\n",
      "In this paper, we show that an adversary can effectively\n",
      "disable the SpamBayes spam ﬁlter with relatively lit-\n",
      "tle system state information and relatively limited con-\n",
      "trol over training data. Our Usenet dictionary attack\n",
      "causes misclassiﬁcation of 36% of ham messages with\n",
      "only 1% control over the training messages, rendering\n",
      "SpamBayes unusable. Our focused attack changes the\n",
      "classiﬁcation of the target message 60% of the time with\n",
      "knowledge of only 30% of the target’s tokens.\n",
      "\n",
      "We also explore two successful defenses. The RONI\n",
      "defense ﬁlters out dictionary attack messages with com-\n",
      "plete success. The dynamic threshold defense also mit-\n",
      "igates the effect of the dictionary attacks. Focused at-\n",
      "tacks are especially difﬁcult to defend against because of\n",
      "the attacker’s extra knowledge; developing effective de-\n",
      "fenses is an important open problem. In future work, we\n",
      "intend to continue reﬁning our defenses.\n",
      "\n",
      "Our attacks and defenses should also apply to other\n",
      "spam ﬁltering systems based on similar learning algo-\n",
      "rithms, such as BogoFilter and the Bayesian component\n",
      "of SpamAssassin although their effect may vary. Similar\n",
      "techniques may also be effective against other learning\n",
      "systems, such as worm or intrusion detection.\n",
      "\n",
      "Acknowledgments\n",
      "\n",
      "We would like to thank Satish Rao, Carla Brodley, and\n",
      "our anonymous reviewers for their useful comments and\n",
      "suggestions on this research.\n",
      "\n",
      "This work was supported in part by the Team for\n",
      "Research in Ubiquitous Secure Technology (TRUST),\n",
      "which receives support from the National Science Foun-\n",
      "dation (NSF award #CCF-0424422), the Air Force Ofﬁce\n",
      "of Scientiﬁc Research (AFOSR #FA9550-06-1-0244),\n",
      "Cisco, British Telecom, ESCHER, Hewlett-Packard,\n",
      "IBM, iCAST, Intel, Microsoft, ORNL, Pirelli, Qual-\n",
      "comm, Sun, Symantec, Telecom Italia, and United Tech-\n",
      "nologies; in part by California state Microelectronics In-\n",
      "novation and Computer Research Opportunities grants\n",
      "(MICRO ID#06-148 and #07-012) and Siemens; and\n",
      "in part by the cyber-DEfense Technology Experimen-\n",
      "tal Research laboratory (DETERlab), which receives\n",
      "support from the Department of Homeland Security\n",
      "Homeland Security Advanced Research Projects Agency\n",
      "(HSARPA award #022412) and AFOSR (#FA9550-07-\n",
      "1-0501). The opinions expressed in this paper are solely\n",
      "those of the authors and do not necessarily reﬂect the\n",
      "opinions of any funding agency, the State of California,\n",
      "or the U.S. government.\n",
      "\n",
      "Figure 5: Effect of the threshold defense on the classi-\n",
      "ﬁcation of ham messages with the dictionary based at-\n",
      "tacks. We use a 10, 000 inbox training set of which 50%\n",
      "are spam. The solid lines represent ham messages clas-\n",
      "siﬁed as spam or unsure while the dashed lines show the\n",
      "classiﬁcation rate of ham messages as spam. Threshold-\n",
      ".05 has a wider range for unsure messages than the\n",
      "Threshold-.10 variation.\n",
      "\n",
      "Several others have recently developed Causative at-\n",
      "tacks against machine learning systems. Chung and\n",
      "Mok [2, 3] present a Causative Availability attack against\n",
      "the Autograph worm signature generation system [10],\n",
      "which infers blocking rules based on patterns observed\n",
      "in trafﬁc from suspicious nodes. The main idea is that\n",
      "the attack node ﬁrst sends trafﬁc that causes Autograph\n",
      "to mark it suspicious, then sends trafﬁc similar to legiti-\n",
      "mate trafﬁc, resulting in rules that cause denial of service.\n",
      "\n",
      "Newsome, Karp, and Song [16] present attacks against\n",
      "Polygraph [15], a polymorphic virus detector that uses\n",
      "machine learning. They primarily focus on conjunction\n",
      "learners, presenting Causative Integrity attacks that ex-\n",
      "ploit certain weaknesses not present in other learning al-\n",
      "gorithms (such as that used by SpamBayes). They also\n",
      "suggest a correlated outlier attack, which attacks a naive-\n",
      "Bayes-like learner by adding spurious features to positive\n",
      "training instances, causing the ﬁlter to block benign traf-\n",
      "ﬁc with those features (a Causative Availability attack).\n",
      "They speculate brieﬂy about applying such an attack to\n",
      "spam ﬁlters; however, several of their assumptions about\n",
      "the learner are not appropriate in the case of SpamBayes,\n",
      "such as that the learner uses only features indicative of\n",
      "the positive class. Furthermore, although they present\n",
      "insightful analysis, they do not evaluate the correlated\n",
      "outlier attack against a real system. Our attacks use sim-\n",
      "ilar ideas, but we develop and test them on a real system.\n",
      "We also explore the value of information to an attacker,\n",
      "and we present and test defenses against the attacks.\n",
      "\n",
      "100\n",
      "\n",
      "90\n",
      "\n",
      "80\n",
      "\n",
      "70\n",
      "\n",
      "60\n",
      "\n",
      "50\n",
      "\n",
      "40\n",
      "\n",
      "30\n",
      "\n",
      "20\n",
      "\n",
      "10\n",
      "\n",
      "l\n",
      "\n",
      "d\n",
      "e\n",
      "f\n",
      "i\n",
      "s\n",
      "s\n",
      "a\n",
      "c\n",
      "s\n",
      "M\n",
      "m\n",
      "a\n",
      "H\n",
      "\n",
      " \n",
      "\n",
      "i\n",
      "\n",
      " \n",
      "t\n",
      "s\n",
      "e\n",
      "T\n",
      "\n",
      " \n",
      "f\n",
      "o\n",
      " \n",
      "t\n",
      "n\n",
      "e\n",
      "c\n",
      "r\n",
      "e\n",
      "P\n",
      "\n",
      "0\n",
      "\n",
      " \n",
      "0\n",
      "\n",
      " \n",
      "\n",
      "No Defense\n",
      "Threshold! 05\n",
      "Threshold! 10\n",
      "\n",
      "2\n",
      "\n",
      "4\n",
      "\n",
      "6\n",
      "\n",
      "8\n",
      "\n",
      "10\n",
      "\n",
      "Percent Control of Training Set\n",
      "\n",
      "\f",
      "[16] James Newsome, Brad Karp, and Dawn Song. Para-\n",
      "graph: Thwarting signature learning by training mali-\n",
      "ciously. In Proceedings of the 9th International Sympo-\n",
      "sium on Recent Advances in Intrusion Detection (RAID\n",
      "2006), September 2006.\n",
      "\n",
      "[17] Gary Robinson. A statistical approach to the spam prob-\n",
      "\n",
      "lem. Linux Journal, March 2003.\n",
      "\n",
      "[18] Cyrus Shaoul and Chris Westbury.\n",
      "\n",
      "(2005-2007), October\n",
      "\n",
      "corpus\n",
      "//www.psych.ualberta.ca/˜westburylab/\n",
      "downloads/usenetcorpus.download.html.\n",
      "\n",
      "2007.\n",
      "\n",
      "A USENET\n",
      "http:\n",
      "\n",
      "[19] Gregory L. Wittel and S. Felix Wu. On attacking statis-\n",
      "tical spam ﬁlters. In Proceedings of the First Conference\n",
      "on Email and Anti-Spam (CEAS), 2004.\n",
      "\n",
      "References\n",
      "\n",
      "[1] Marco Barreno, Blaine Nelson, Russell Sears, An-\n",
      "thony D. Joseph, and J. D. Tygar. Can machine learn-\n",
      "ing be secure? In Proceedings of the ACM Symposium\n",
      "on InformAtion, Computer, and Communications Security\n",
      "(ASIACCS’06), March 2006.\n",
      "\n",
      "[2] Simon P. Chung and Aloysius K. Mok. Allergy attack\n",
      "In Recent Ad-\n",
      "against automatic signature generation.\n",
      "vances in Intrusion Detection (RAID), pages 61–80, 2006.\n",
      "\n",
      "[3] Simon P. Chung and Aloysius K. Mok. Advanced allergy\n",
      "attacks: Does a corpus really help? In Recent Advances\n",
      "in Intrusion Detection (RAID), pages 236–255, 2007.\n",
      "\n",
      "[4] Gordon Cormack and Thomas Lynam. Spam corpus cre-\n",
      "ation for TREC. In Proceedings of the Second Conference\n",
      "on Email and Anti-Spam (CEAS 2005), July 2005.\n",
      "\n",
      "[5] Nilesh Dalvi, Pedro Domingos, Mausam, Sumit Sanghai,\n",
      "In Pro-\n",
      "and Deepak Verma. Adversarial classiﬁcation.\n",
      "ceedings of the Tenth ACM SIGKDD International Con-\n",
      "ference on Knowledge Discovery and Data Mining, pages\n",
      "99–108, Seattle, WA, 2004. ACM Press.\n",
      "\n",
      "[6] Ronald A. Fisher. Question 14: Combining independent\n",
      "tests of signiﬁcance. American Statistician, 2(5):30–30J,\n",
      "1948.\n",
      "\n",
      "[7] Paul Graham. A plan for spam.\n",
      "\n",
      "http://www.\n",
      "\n",
      "paulgraham.com/spam.html, August 2002.\n",
      "\n",
      "[8] Christoph Karlberger, G¨unther Bayler, Christopher\n",
      "Kruegel, and Engin Kirda. Exploiting redundancy in\n",
      "natural language to penetrate Bayesian spam ﬁlters.\n",
      "In\n",
      "WOOT’07: Proceedings of the ﬁrst conference on First\n",
      "USENIX Workshop on Offensive Technologies, 2007.\n",
      "\n",
      "[9] Michael Kearns and Ming Li. Learning in the pres-\n",
      "ence of malicious errors. SIAM Journal on Computing,\n",
      "22(4):807–837, 1993.\n",
      "\n",
      "[10] Hyang-Ah Kim and Brad Karp. Autograph: Toward auto-\n",
      "mated, distributed worm signature detection. In USENIX\n",
      "Security Symposium, August 2004.\n",
      "\n",
      "[11] Bryan Klimt and Yiming Yang.\n",
      "\n",
      "Introducing the Enron\n",
      "corpus. In Proceedings of the First Conference on Email\n",
      "and Anti-Spam (CEAS), July 2004.\n",
      "\n",
      "[12] Daniel Lowd and Christopher Meek. Adversarial learn-\n",
      "ing. In Proceedings of the Eleventh ACM SIGKDD Inter-\n",
      "national Conference on Knowledge Discovery and Data\n",
      "Mining, pages 641–647, 2005.\n",
      "\n",
      "[13] Daniel Lowd and Christopher Meek. Good word attacks\n",
      "on statistical spam ﬁlters. In Proceedings of the Second\n",
      "Conference on Email and Anti-Spam (CEAS), 2005.\n",
      "\n",
      "[14] Tony Meyer and Brendon Whateley. SpamBayes: Ef-\n",
      "fective open-source, Bayesian based, email classiﬁcation\n",
      "system. In Proceedings of the First Conference on Email\n",
      "and Anti-Spam (CEAS), July 2004.\n",
      "\n",
      "[15] James Newsome, Brad Karp, and Dawn Song. Poly-\n",
      "graph: Automatically generating signatures for polymor-\n",
      "phic worms. In Proceedings of the IEEE Symposium on\n",
      "Security and Privacy, pages 226–241, May 2005.\n",
      "\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pdf_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb0eb38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citymobil Data Meetup #1 | Switchback эксперименты и сетевые эффекты / Блог компании Ситимобил / Хабр\n",
      "Хабр\n",
      "β\n",
      "Открыть список\n",
      "Как стать автором\n",
      "Все потоки\n",
      "Разработка\n",
      "Администрирование\n",
      "Дизайн\n",
      "Менеджмент\n",
      "Маркетинг\n",
      "Научпоп\n",
      "Поиск\n",
      "Профиль\n",
      "Обновить\n",
      "185.34\n",
      "Рейтинг\n",
      "Ситимобил\n",
      "Творим городскую мобильность\n",
      "leleles\n",
      "сегодня в 18:30\n",
      "Citymobil Data Meetup #1 | Switchback эксперименты и сетевые эффекты\n",
      "Блог компании Ситимобил\n",
      "Всем еще раз привет! На связи с вами Артем Солоухин. Я представляю команду surge pricing, подразделение эффективности и маркетплейса «Ситимобил». Сегодня мы с вами немного поговорим про switchback эксперименты и про сетевые эффекты. Начнем с небольшого интро в том, чем занимается наша команда, чтобы стало понятно, почему нас волнует то, о чем мы сегодня поговорим.  Далее немного обсудим сетевой эффект, поговорим про switchback, решает ли он проблему сетевого эффекта и насколько. Подведем какие-то итоги. Итак, погнали.\n",
      "Что же делает наша команда surge pricing? Возможно, вы замечали, когда открывали приложение такси вот такую иконку повышающего коэффициента. Собственно, мы это и делаем. Но еще мы лечим вот такую вот беду, когда машина не назначается или подается долго. В том числе мы помогаем избегать таких ситуаций в сервисе такси. Так что если вы очень сильно торопитесь к девушке на свидание или к родителям на день рождения и так далее, то вы смело можете рассчитывать на нас. Мы будем стараться всеми способами сделать так, чтобы дисбаланса не было, чтобы вы могли получить назначение машины тогда, когда это действительно нужно, и чтобы это было не слишком долго.\n",
      "Но если более глобально, то в surge pricing мы боремся за то, чтобы сделать пассажиров и водителей более счастливыми, или как минимум, сделать так, чтобы сервис такси, как уже подметил, мог представлять услуги такси. Одной из ключевых проблем, которую мы решаем, является wild goosechase. Это такое состояние, когда мы заставляем водителя ехать далеко, а пассажиров ждать долго.\n",
      "Большая часть времени водителя в такой ситуации приходится на путь к пассажирам и доход может оказаться ниже по сравнению с работой в обычное время. Так агрегатор рискует лишиться водителей и пассажиров. Если же у вас возникает вопрос о том, почему здесь такой странный термин, wild goose chase, то здесь есть две причины его использования. Первое – это применение термина Кастильо, одного из авторов фундаментальных трудов о динамическом ценообразовании такси. А вторая, по сути, исходная – это то, что в разговорном английском языке wild goose chaseотносится к таким длительным расточительным, в конечном счете тщетным преследованиям недостижимой цели.\n",
      "Давайте попробуем рассмотреть эту ситуацию на более ярком примере. Допустим, у нас есть некоторое скопление водителей возле бизнес-центра и несколько пассажиров в немного отдаленном районе. Допустим, у нас нет никакого механизма для регулирования объемов спроса и предложения. Водитель назначается по наивному алгоритму. То есть для первого заказавшего назначается ближайший доступный водитель.  В таком случае при резком скачке объема спроса вот здесь сначала ребята будут разбирать водителей, которые поблизости, а потом будут забирать все дальше и дальше свободных водителей.\n",
      "В то же время, если в следующую секунду вот эти ребята захотят заказать такси, то у них уже не будет возможности получить назначение вот этих вот довольно близко находящихся водителей, потому что они уже здесь заняты. Один из них может получить какое-то назначение довольно далекого водителя, а второй, может быть, вообще ничего не получит. Это довольно плохая ситуация, понятное дело. Но также если посмотреть на то, что вообще происходит, с точки зрения пассажиров и водителей, то по сути, пассажиры  вот здесь с увеличением дисбаланса ждут все дольше, так же как здесь и вероятность назначения машины становится все меньше. Никому это неинтересно.\n",
      "Водителям не нужен большой холостой ход, большие расходы на бензин без оплаты. Пассажирам неинтересно долго ждать назначение машины, неинтересно создавать заказы, не получать на них назначение машины, неинтересно ждать долго подачи машины. Много чего неполезного происходит в этой ситуации. Кроме этого если обращаться к практике, то если реально водители назначаются очень далеко, то пассажиры могут не дождаться и отменить заказ через пару-тройку минут после нахождения машины. И тогда для водителя все становится вовсе очень плохо. Он не получает какого-то заработка за поездку, потому что она не совершается. У пассажира тоже все не очень хорошо, потому что он в итоге никуда не уехал.\n",
      "Одно из решений таких вот ситуаций дисбаланса – это изменение цен как вверх, так и вниз. Такое тоже бывает. Есть, конечно, и другие решения. Их много на самом деле. Не только ценами можно регулировать дисбаланс. Что касается цен, они могут быть регулированы вниз в той ситуации, когда водителей слишком много, а пассажиров мало. Такое тоже бывает в сервисах такси.\n",
      "Подводя итог, мы в surge pricing пытаемся добиться того, чтобы дисбалансов в системе было как можно меньше, чтобы какая-то общая полезность или эффективность агентов нашего маркетплейса не ухудшалась, росла. Мы пытаемся сделать так, чтобы все были довольны. Вообще, surge pricing – это такая крутая, классная, захватывающая тема. Но давайте перейдем к нашей основной теме.\n",
      "Наш алгоритм surge pricing требует проведения многих экспериментов, потому что это довольно сложная штука. Иногда сложно понять, что же для нас лучше, что хуже. Мы постоянно экспериментируем, чтобы точно это знать. Некоторые механики проведения экспериментов мы применять не можем, потому что есть определенные проблемы. Одна их таких проблем – сетевой эффект.\n",
      "В качестве примера сетевого эффекта можно взять модель ухудшающего эксперимента, в которой участвуют два пользователя. Они делят одного водителя. По сути, один из пользователей может в такой плохой ситуации, когда сетевой эффект проявляется, может принадлежать группе А, второй пользователь может принадлежать группе Б. Тогда здесь сценариев может быть много. В случае если пользователь А закажет раньше, чем пользователь Б, то водитель может приехать к нему первее. Точнее, он может с большей вероятностью туда назначиться при прочих равных, потому что здесь повышающий коэффициент, например, есть, а здесь его нет.\n",
      "В случае, если мы проводим ухудшающий эксперимент. То есть в одной контрольной группе механизм есть   . В данном случае мы говорим про механизм динамического ценообразования, а значит, повышенные цены. В другой группе его нет. Соответственно, здесь повышенные цены, здесь не повышенные цены. Водитель может предпочесть поехать сюда. С другой стороны, этот пассажир может отказаться от поездки, потому что здесь повышающая цена, таким образом, сохранить водителя для другого пассажира.\n",
      "Третий момент, что вот этот пассажир может заказать на 5 с раньше, чем этот пассажир, таким образом, первее его заказ может предложиться водителю. Здесь сценариев может быть довольно много разных. Так или иначе, эти два чувака друг на друга влияют, так как они объединены какой-то одной водительской базой, одним водителем, двумя, тремя. Неважно.\n",
      "На самом деле примерно такие же сетевые эффекты могут возникать в той или иной мере и в ваших сервисах. Например, когда несколько курьеров доступны для назначения сразу на группу А и группу Б. Но просто представьте, что здесь нарисована не машинка, а курьер. Ровно такая же ситуация будет. Или, например, когда у вас в интернет-магазине остался всего один товар на полке. Он доступен для продажи нескольким группам. Из группы А человек может зайти на страницу с этим товаром и из группы Б. Кто первый закажет, тому и хорошо. Второй будет вынужден искать альтернативу или вовсе отказываться от покупки. Вы можете подумать о своих сетевых эффектах сами. Но вообще, можете не особо расстраиваться по этому поводу, потому что есть некоторые способы, как это побороть. Давайте попробуем посмотреть на один из них, то есть switchback.\n",
      "Метод switchback, как я уже сказал, применяется для проверки моделей, когда традиционное распределение на группы не всегда эффективно.\n",
      "На скриншоте справа изображен наш исторический момент. Это одна из первых раскрасок Москвы по switchback у нас в «Ситимобил» в 2019 году, когда мы пробовали геосплитование. Как понятно из изображения, мы разделяем не пользователей, а некоторую площадь, перемешиваем эту разбивку через каждые n минут. Таким образом, если вы совершаете в какой-то момент какое-то действие в приложении «Ситимобил» в синей области, то мы раскрашиваем ваши действия в группу А. Всю последующую цепочку действий – заказ такси, назначенную машину, поданную машину, поездку – вот это все мы атрибуцируем группой А. В случае если вы заказываете в зеленой зоне, то мы на вас навешиваем ярлык группы Б. Все события так помечаем.\n",
      "Здесь важно подчеркнуть, что мы раскрашиваем рандомно каждые n минут. То есть эта разбивка не статична все время проведения эксперимента, а она как-то перемешивается. Кроме этого здесь указаны районы, которые раскрашены в разные группы. Но на самом деле можно делать полностью весь город в одной группе, условно всю Москву закрашивать группой А или группой Б. Так часто делают. Здесь нужно исходить из предпосылок вашего бизнеса.\n",
      "Также важно подбирать для вот этого switchback эксперимента гиперпараметры. Какие здесь есть гиперпараметры. Мы уже немного затронули. Первый из гиперпараметров – это площадь. Можно хоть на весь город, хоть на всю страну поставить группу А или группу Б, а можно лишь на один район или и того меньше. Здесь нужно исходить из того, как себя ведут ваши метрики, какая их природа.\n",
      "Допустим, у нас в сервисе такси может быть так, что радиус поиска машины для созданного заказа может быть ограничен. Допустим, он ограничен тремя километрами. В таком случае понятное дело, что если мы возьмем какую-то фигуру, у которой радиус будет меньше, чем 3 км, то от центра этой фигуры мы сможем захватить другую группу из другой площади, в случае если мы раскрашиваем таким образом, что у нас соседняя область есть и она раскрашена в другую группу.\n",
      "С другой стороны, если взять слишком большую область, то тоже может быть удобно. Может захватиться большой район, в котором постоянно аномалии, он может залететь в одну из групп в большей степени. Здесь нужен какой-то компромисс. Его нужно, скорее всего, искать по тому, как себя ведет ваш бизнес, какая его природа, какие там предпосылки есть. И второе. Сходится ли у вас А/А тест при данном гиперпараметре, который вы подобрали вручную.\n",
      "Второй гиперпараметр – это время. Вы можете сплитовать. Каждый час перемешивать на Москве разные фигуры, раскрашивать группа А, группа Б каждые два часа, каждый день. Неважно. Здесь зависит от ваших бизнес-реалий, от того, насколько хорошо сходится ваш АА тест. Смотрите, насколько большая дисперсия в наблюдениях, сходятся ли вообще по выбранному статкритерию ваши метрики, которые вы решили проверять в эксперименте.\n",
      "Если говорить о том, какие результаты применения switchback, как вообще можно подойти к тому, как это оценить, то например, в сервисе такси мы можем сказать, что сетевому эффекту подвергаются пассажиры. Также и водители, но в том числе пассажиры. Их можно задать как вектор из таких параметров как время и координаты.\n",
      "Сетевой эффект в некотором его роде можно определить как функцию от дельты во времени и дельты в дистанции между точками А, которые они ставят. Условно, если представить, что у нас есть два пользователя, один из них ставит точку А на севере города Москва, а другой на юге, то нам это нестрашно, с точки зрения проведения эксперимента, потому что вряд ли они будут претендовать на одну и ту же водительскую базу. С другой стороны, если два пользователя будут ставить точку в одной координате, но один поставит в 10 часов утра, другой в 12 часов дня, то в таком случае тоже ничего страшного не происходит, потому что у них будет разная водительская база, разное время.\n",
      "Если пользователи делают заказ примерно в одно время, в одной географической площади, условно, на 100 метров друг от друга отдалены, в таком случае наверняка они будут претендовать на одну и ту же водительскую базу и как-то друг на друга влиять. Если задать некоторую функцию, попробовать численно выразить такой сетевой эффект по классическому А/В эксперименту, switchback, я не буду раскрывать конкретику, тем более здесь у нас наши любимые друзья из Яндекс.Такси, в общем, если это сделать, то сетевой эффект, посчитанный по классическому А/В тестированию где-то в  три раза выше, чем по switchback.\n",
      "Это кажется довольно вкусно. К тому же если там еще сходятся А/А тесты, все понятно по результатам экспериментов, то кажется, что вполне хорошая механика.\n",
      "Но у нее есть некоторые проблемы. Мы уже затрагивали вопрос подбора гиперпараметров в виде площади и времени. Здесь есть такой важный момент. На самом деле сетевой эффект не полностью исключается в switchback. Он сохраняется на границах переключения моделей. Представьте, что у вас есть модель, которая с 18 часов до 18.59 минут раскрасила город в группу А, у которой динамическое ценообразование отключено и цены очень дешевые. В таком случае за вот этот час всех водителей разобрали, потому что все очень дешево, хорошо для пассажиров. К 18.59.59 свободных водителей в городе нет. Тут наступает 19 часов. Город раскрашивается в группу В, в которой динамический коэффициент включен. Мы сталкиваемся с первой ситуацией. Водителей вообще нет. Даже если кто-то попробует заказать, то он не получит назначение машины. Второй момент. Вы будете вынуждены как-то балансировать. Там же работает алгоритм балансирования. Соответственно, там могут повышаться цены и так далее. Соответственно, тоже некоторым образом влиять на поведение пользователей.\n",
      "Если переключения слишком частые, условно, каждые 3 минуты одна группа полностью опустошает город от водителей, а вторая дожидается переключения, когда переключаемся на surge, ставит цены слишком высокими. Никто не заказывает. Потом через 3 минуты освобождаются водители, их снова разбирают по дешевым ценам. Получается не очень хорошая ситуация. Поэтому нужно подбирать здесь окошко осторожно.\n",
      "Также может возникать сетевой эффект на границах агрегируемой площади. Условно, если у вас площадь не целый город, а какая-то его частичка, у вас есть два пользователя, которые находятся на границах, близких друг к другу, в таком случае они могут претендовать на водителей из соседней площади, тоже создавать сетевой эффект.\n",
      "Кроме этого следующая такая проблема – это то, что один пользователь, который заходит в разные моменты времени, может видеть разные варианты функционала. Опять же мы здесь сплитуем не пользователей, а географию, соответственно, по времени. Если пользователь зашел в момент, когда на конкретной площади есть группа А, а потом через секунду ваш механизм сплитования перекрасил эту область в группу Б, он тоже зашел через секунду, то сначала он увидит механизм группы А, потом он увидит механизм группы Б.\n",
      "Может быть, немного поменяет свое решение относительно покупки товара, услуги. Еще что следует из этой проблемы, это то, что невозможно применять эксперименты с изменением графической составляющей. Точнее, кажется странным если вы будете пользователю показывать утром, днем и вечером, в разные моменты времени разный дизайн. И даже еще более странно, если это будет происходить, если он в один и тот же момент времени ставя точку А на севере Москвы или на юге, будет видеть разные дизайны приложений.\n",
      "Наверное, здесь switchback более хорошая вещь для таких подкапотных штук типа ценообразования, механизма распределения заказов, скидок и так далее. Но также рекомендуем применить следующие фишки. Первое. Используйте А/А/В разбиение или А/В/В разбиение. В принципе, это на самом деле касается не только switchback экспериментов, но в том числе их.\n",
      "Вы делите свой город таким образом, чтобы у вас в группе А1 и группе А2 накопилось примерно по 25% наблюдений, в группе накопилось 50%. Таким образом, в конце эксперимента вы можете сравнить группу А1 с группой А2, понять, сходится ли там та метрика, которую вы хотите проверить в эксперименте. Если там все сходится, если никаких вопросов нет, тогда вы можете доверять результату сравнения конкатенированного набора данных  А1 и А2 с В. switchback и вообще, любой эксперимент, который бы вы ни проводили, со сплитованием по хешу от id, чему угодно, вы можете получить такую ситуацию, что в одну из групп залетит какая-то аномалия. В одной из групп окажутся те пользователи, которые ведут себя немного иначе, нежели чем пользователи в другой группе. Заведомо ваш эксперимент будет обречен либо на успех, либо на провал. Здесь как повезет. Может быть, скос будет в ту сторону, в которую нужно, может быть нет. Черт знает. Лучше проверить.\n",
      "Второе. Оптимально выбирать не слишком большое окно разбиений, слишком маленькое. Мы об этом поговорили в блоке с проблемами. Также здесь подчеркну, что надо подбирать такие гиперпараметры, чтобы ретроспективно А/А тест и уже на проде выкаченный сходился.\n",
      "Третье. Нужно выбирать площади с очень маленькими статистиками и выбросами по конверсиям из механизма сплитования. Здесь важный момент. Мы в switchback работаем с географической площадью. Соответственно, мы должны понимать, что у нас те единицы, которые будут сплитоваться, примерно похожей природы. Если это не так, то тот выброс, который есть в какой-то географической зоне, который постоянно наблюдается, может повлиять на смещение или дисперсию вашего эксперимента.\n",
      "Четвертое. Нужно осторожно очищать данные после проведения эксперимента. Если вы очищаете всякие выбросы, наблюдения на границе переключения сплитов, если на границе площади очищаете наблюдения, то важно сделать так, чтобы у вас не осталось 10% от того набора наблюдений, который был изначально. Здесь нужна какая-то мера. Возможно, если у вас не сходится А/А тест, то стоит его подержать подольше, а не применять кучу очисток. Или подобрать другой город, или посмотреть на то, а все ли у вас хорошо технически в эксперименте. Возможно, у вас где-то есть техническая проблема, какая-то ошибка, что иногда бывает.\n",
      "Таким образом, можно сделать следующие выводы. Первое. Если у вас большой сетевой эффект или вы подозреваете, что он у вас есть, или если у вас проводятся обычные классические А/В тесты и вы видите, что все плохо сходится, при этом вы подозреваете, что у вас сетевой эффект, тогда вы можете попробовать с помощью switchback снизить сетевой эффект. Возможно, у вас починится сходимость групп А/А.\n",
      "Второе. Если у вас геосервис с юнитами во времени, то switchback может оказаться удобной штукой. Например, мы не ставим персональные цены для пользователей в динамическом ценообразовании. Мы это делаем для географической площади, для времени. Нам гораздо удобнее работать с этим юнитом, с этой единицей. Если бы мы пытались сделать какой-то тест на пользователя, то нам пришлось бы дорабатывать какие-то механики, делать поверх какие-то вещи нашего механизма. А так мы можем просто взять и использовать switchback. Если по А/А тесту нас все устраивает, то вообще нет никаких причин, чтобы его не использовать.\n",
      "Третье. switchback имеет свои недостатки и преимущества. Надо об этом помнить. Не забывать о том, что есть большая работа по его настройке.\n",
      "Полезные ссылочки\n",
      "Switchback-эксперименты в Ситимобил: Часть 1. Зачем это нужно\n",
      "Testing for arbitrary interference on experimentation platforms\n",
      "Случайность над случайностью или в поисках \"Социального эффекта\"\n",
      "Switchback Tests and Randomized Experimentation Under Network Effects at DoorDash\n",
      "Switchback-тестирование. Как бороться с социальными эффектами в A/B-тестах\n",
      "Ваш алгоритм прибыл\n",
      "Теги:\n",
      "data science\n",
      "switchback\n",
      "meetup\n",
      "расшифровка\n",
      "Хабы:\n",
      "Блог компании Ситимобил\n",
      "Рейтинг\n",
      "0\n",
      "Добавить в закладки\n",
      "0\n",
      "Комментарии\n",
      "0\n",
      "Ситимобил\n",
      "Творим городскую мобильность\n",
      "Сайт\n",
      "5.2\n",
      "Карма\n",
      "2.1\n",
      "Рейтинг\n",
      "@leleles\n",
      "Пользователь\n",
      "Комментарии\n",
      "Комментировать\n",
      "Похожие публикации\n",
      "15  сентября   в 10:59\n",
      "Citymobil Data Meetup #2\n",
      "Всего голосов 8: ↑7 и ↓1\n",
      "+6\n",
      "Просмотры\n",
      "111\n",
      "Добавить в закладки\n",
      "0\n",
      "Комментарии\n",
      "0\n",
      "31  августа   в 13:00\n",
      "Эксперименты в Ситимобил. Эпизод 2: Атака тестов на Switchback\n",
      "Всего голосов 12: ↑11 и ↓1\n",
      "+10\n",
      "Просмотры\n",
      "1.7K\n",
      "Добавить в закладки\n",
      "11\n",
      "Комментарии\n",
      "5\n",
      "28  мая   в 13:10\n",
      "Все что вы (не) хотели знать о Data Science\n",
      "Всего голосов 18: ↑18 и ↓0\n",
      "+18\n",
      "Просмотры\n",
      "12K\n",
      "Добавить в закладки\n",
      "57\n",
      "Комментарии\n",
      "7\n",
      "Лучшие публикации за сутки\n",
      "сегодня в 10:02\n",
      "Железа и баек ностальгии пост\n",
      "Всего голосов 103: ↑103 и ↓0\n",
      "+103\n",
      "Просмотры\n",
      "12K\n",
      "Добавить в закладки\n",
      "25\n",
      "Комментарии\n",
      "36\n",
      "сегодня в 14:03\n",
      "Если вы думаете, что в энтерпрайзе сервис лучше, а жизнь ярче, то у меня есть, что рассказать\n",
      "Всего голосов 47: ↑46 и ↓1\n",
      "+45\n",
      "Просмотры\n",
      "4.7K\n",
      "Добавить в закладки\n",
      "18\n",
      "Комментарии\n",
      "7\n",
      "сегодня в 11:30\n",
      "Jetpack Microbenchmark — тестируем производительность кода\n",
      "Всего голосов 37: ↑37 и ↓0\n",
      "+37\n",
      "Просмотры\n",
      "687\n",
      "Добавить в закладки\n",
      "29\n",
      "Комментарии\n",
      "0\n",
      "вчера в 21:59\n",
      "Нужно больше ядер: новые чипы разных компаний с десятками и сотнями ядер для высокопроизводительных систем\n",
      "Всего голосов 32: ↑32 и ↓0\n",
      "+32\n",
      "Просмотры\n",
      "4.5K\n",
      "Добавить в закладки\n",
      "13\n",
      "Комментарии\n",
      "6\n",
      "сегодня в 10:32\n",
      "Как устроен The Update Framework (TUF). Обзор технологии безопасного обновления ПО\n",
      "Всего голосов 31: ↑31 и ↓0\n",
      "+31\n",
      "Просмотры\n",
      "1.3K\n",
      "Добавить в закладки\n",
      "15\n",
      "Комментарии\n",
      "0\n",
      "Информация\n",
      "Дата основания\n",
      "14  мая  2007\n",
      "Местоположение\n",
      "Россия\n",
      "Сайт\n",
      "city-mobil.ru\n",
      "Численность\n",
      "1 001–5 000 человек\n",
      "Дата регистрации\n",
      "27  декабря  2019\n",
      "Блог на Хабре\n",
      "сегодня в 18:30\n",
      "Citymobil Data Meetup #1 | Switchback эксперименты и сетевые эффекты\n",
      "Просмотры\n",
      "45\n",
      "Комментарии\n",
      "0\n",
      "8  сентября   в 12:58\n",
      "Эффективный DevOps\n",
      "Просмотры\n",
      "5.9K\n",
      "Комментарии\n",
      "0\n",
      "31  августа   в 13:00\n",
      "Эксперименты в Ситимобил. Эпизод 2: Атака тестов на Switchback\n",
      "Просмотры\n",
      "1.7K\n",
      "Комментарии\n",
      "5\n",
      "30  августа   в 10:28\n",
      "Даже один в поле воин: азы юнит-экономики\n",
      "Просмотры\n",
      "17K\n",
      "Комментарии\n",
      "19\n",
      "25  августа   в 12:02\n",
      "Как мы за квартал подготовили редизайн водительского приложения\n",
      "Просмотры\n",
      "2.3K\n",
      "Комментарии\n",
      "0\n",
      "Ваш аккаунт\n",
      "Войти\n",
      "Регистрация\n",
      "Разделы\n",
      "Публикации\n",
      "Новости\n",
      "Хабы\n",
      "Компании\n",
      "Авторы\n",
      "Песочница\n",
      "Информация\n",
      "Устройство сайта\n",
      "Для авторов\n",
      "Для компаний\n",
      "Документы\n",
      "Соглашение\n",
      "Конфиденциальность\n",
      "Услуги\n",
      "Реклама\n",
      "Тарифы\n",
      "Контент\n",
      "Семинары\n",
      "Мегапроекты\n",
      "Facebook\n",
      "Twitter\n",
      "VK\n",
      "Telegram\n",
      "Youtube\n",
      "Яндекс Дзен\n",
      "Настройка языка\n",
      "О сайте\n",
      "Техническая поддержка\n",
      "Вернуться на старую версию\n",
      "© 2006–2021\n",
      "«\n",
      "Habr\n",
      "»\n"
     ]
    }
   ],
   "source": [
    "print(html_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c938ed10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Слайд 1\n",
      "Сначала я расскажу про линейную классификацию: то есть как применять линейные модели к задачам классификации.\n",
      "\n",
      "Слайд 2\n",
      "И начну о самом простом виде классификации — бинарной классификации, где ответы принимают значения из множества −1 и +1, то есть всего 2 возможных значения. Чтобы работать с той или иной моделью, нужно уметь отвечать на 3 вопроса: первый — это как мы измеряем качество, как устроен функционал ошибки; второй — как устроено семейство алгоритмов, то есть то множество алгоритмов, из которого мы выбираем наилучший с точки зрения функционала; и третий — это как мы обучаем алгоритм, то есть выбираем лучший из семейства с точки зрения функционала ошибки. Сейчас я расскажу о семействе алгоритмов, а в далее— о том, как измерять их ошибки и как обучать эти алгоритмы. \n",
      "Слайд 3\n",
      "Про линейную регрессию уже был же доклад. Линейные классификаторы устроены очень похоже. В линейной регрессии мы складывали все признаки с весами, при этом вес при j-том признаке обозначали как wj-тое, и после этого суммирования проявляли еще свободный коэффициент w0, который также называется сдвигом. В случае с регрессией нас эта формула полностью устраивала, поскольку она принимала вещественные значения, теперь же алгоритм должен возвращать бинарные значения: −1 или +1. Чтобы добиться этого, можно просто взять знак от этого выражения, именно это и будет видом линейного классификатора. \n",
      "Слайд 4\n",
      "Заметим, что формула не очень однородная, в ней есть свободный коэффициент, чтобы убрать его, давайте просто добавим еще один признак выборки, константный признак, который на каждом объекте принимает значение 1, единичный признак. В этом случае свободный коэффициент уже не нужен, его роль будет выполнять вес при этом константном признаке, и формула приобретает такое значение. Заметим, что по сути такая взвешенная сумма признаков — это скалярное произведение вектора весов на вектор признаков, и значит итоговый вид линейного классификатора — это знак скалярного произведения w на x, этой формулой мы и будем пользоваться дальше. \n",
      "Слайд 5\n",
      "Давайте разберемся, какой геометрический смысл у линейного классификатора. В случае с линейной регрессией мы обсуждали, что это по сути приближение зависимости ответа от признаков с помощью прямой или гиперплоскости. Что же это будет в случае с классификацией? Для этого давайте запишем то, что стоит под функцией знака — скалярное произведение w на x, и приравняем к 0, получим такое уравнение. Давайте нарисуем вектор весов w и будем искать все такие точки x, которые удовлетворяют этому уравнению, то есть все такие точки, для которых скалярное произведение этой точки, этого вектора на w = 0. Равенство нулю скалярного произведения означает, что угол между этими векторами = 90 градусов, то есть что они перпендикулярны. Получается, что точки, удовлетворяющие этому уравнению — это все векторы, ортогональные вектору весов. Из аналитической геометрии известно, что это множество представляет собой плоскость. Получается, что уравнение задает плоскость, более того, с одной стороны от этой плоскости значение скалярного произведения будет больше 0, а с другой стороны от плоскости — меньше 0. Получается, что линейный классификатор проводит гиперплоскость в пространстве признаков, и все объекты, которые с одной стороны, относят к классу +1, а те, которые с другой стороны — к классу −1.\n",
      "Слайд 6\n",
      "В случае с двумя признаками это выглядит как-то так: у нас есть выборка, мы проводим разделяющую прямую, и все объекты, которые с одной стороны, относим к классу −1, все, которые с другой стороны, относим к классу +1.\n",
      "Слайд 7\n",
      "Заметим, что линейные классификаторы вычисляют значение скалярного произведения, которое имеет вещественное значение, а затем берет только знак, отбрасывая часть информации. При этом, наверное, само значение скалярного произведения тоже имеет смысл. Действительно, оказывается, что если мы возьмем модуль этого скалярного произведения и отнормируем его, то есть поделим на норму вектора весов, то это выражение будет равно расстоянию от точки x до гиперплоскости, которая задается вектором нормали, вектором весов w. Получается, что линейный классификатор сначала измеряет расстояние от точки до гиперплоскости со знаком и дальше смотрит лишь на знак, то есть на то, с какой стороны от гиперплоскости лежит эта точка.\n",
      "Слайд 8\n",
      "Так мы приходим к очень важному понятию в линейной классификации — к понятию отступа. Отступом называется выражение вида: скалярное произведение вектора весов на объект, умноженное на истинный ответ на этом объекте, который, напомню, равен +1 и −1. Какой смысл у этого выражения? Давайте обратим внимание: если скалярное произведение имеет положительный знак и истинный ответ равен +1 — это верная классификация и произведение скалярного произведения на истинный ответ будет больше 0. Если скалярное произведение меньше 0, и истинный ответ равен −1, то это тоже будет правильная классификация, и их произведение снова будет больше 0. Если же знак ответа и знак скалярного произведения противоположные, то классификация будет ошибочной и знак отступа будет меньше 0. Получается, что отступ — это некоторая величина, которая характеризует корректность ответа. Если отступ больше 0, то алгоритм дает корректный ответ, если отступ меньше 0 — алгоритм дает некорректный ответ. При этом само абсолютное значение отступа свидетельствует о расстоянии от точки до разделяющей гиперплоскости. Принято считать, что если точка находится рядом с разделяющей гиперплоскостью, то классификация неуверенная, наш алгоритм сомневается, к какому классу относить ее, если же точка находится далеко от разделяющей гиперплоскости, то классификация уверенная, при этом, если алгоритм прав, то он просто уверен в этом, все хорошо, если же алгоритм ошибается, и при этом отступ по модулю очень большой, это означает, что алгоритм очень сильно ошибается в классификации этого объекта, возможно, этот объект является выбросом и никак не вписывается в нашу модель, или же алгоритм не подходит для решения этой задачи.\n",
      "Слайд 9\n",
      "В случае с классификацией возникает вполне естественный подход. У нас ответов конечное число. Соответственно, можем требовать точного совпадения класса, предсказанного алгоритмом A(Xi), и истинного класса Yi. Соответственно, функционал, который мы получаем, — это доля неправильных ответов, доля ошибочных ответов. Он записывается вот так. Это сумма индикаторов того, что предсказанный класс A(Xi) не совпал с истинным классом Yi. И все это усредняется по всей обучающей выборке.\n",
      "Слайд 10\n",
      "Давайте вспомним, что в прошлый раз мы изучали понятие отступа, который позволяет понять, ошибается или нет алгоритм на данном объекте. Отступ на этом объекте задается как произведение истинного ответа Yi на скалярное произведение вектора весов W на вектор признаков Xi. Если отступ меньше нуля, то алгоритм ошибается на данном объекте. Соответственно, наш функционал долю неправильных ответов можно переписать, как среднее значение индикатора того, что отступ на (i) объекте меньше нуля.\n",
      "\n",
      "Слайд 11\n",
      "Давайте посмотрим, как выглядит функция, которая стоит под знаком суммы. Индикатор того, что отступ меньше нуля. По оси \"Икс\" отложим отступ Mi, отступ на этом объекте, по оси \"Игрек\" — значение функции потерь, значение индикатора. Мы видим, что эта функция пороговая. Она равна единице, если отступ меньше нуля, и нулю, если отступ больше нуля.\n",
      "\n",
      "Слайд 12\n",
      "Эта функция является разрывной, у нее разрыв в нуле. Из-за этого ее нельзя оптимизировать градиентными методами. Конечно, можно воспользоваться методами негладкой оптимизации, но они довольно сложные в реализации и не дают гарантии сходимости к локальному оптимуму. Поэтому давайте попробуем как-то изменить задачу, чтобы она стала гладкой.\n",
      "Слайд 13\n",
      "Для этого возьмем индикатор того, что отступ меньше нуля, нашу пороговую функцию потерь. Оценим сверху этот индикатор некоторой гладкой функцией \"L с волной\", которая также зависит от отступа M. То есть это должна быть такая функция, которая больше или равна единице, если отступ отрицательный, и больше или равна нуля, если отступ положительный. Далее, используя данную верхнюю оценку \"L с волной\", мы можем оценить весь функционал ошибки, весь функционал доли неверных ответов. Верхняя оценка на этот функционал будет выглядеть так: это среднее значение нашей гладкой функции потерь \"L с волной\" по всей обучающей выборке.\n",
      "\n",
      "Слайд 14\n",
      "Обратите внимание: в этом случае мы будем минимизировать не долю неправильных ответов, а среднее значение нашей гладкой функции потерь \"L с волной\". При этом мы надеемся, что если мы приведем к нулю данное среднее значение гладкой функции, то при этом прижмется к нулю и то, что она оценивает сверху, прижмется к нулю доля неправильных ответов. Но при этом, конечно же, нет никаких гарантий, что, минимизируя верхнюю оценку, мы будем точно минимизировать и то, что она оценивает, то есть долю неправильных ответов. Но при этом мы получаем очень удобную, хорошую гладкую задачу минимизации.\n",
      "Слайд 15\n",
      "Давайте рассмотрим несколько примеров таких гладких оценок. Например, это может быть логистическая функция потерь L(M), которая записывается как логарифм, под которым стоит единица плюс экспонента от минус отступа. Она используется в логистической регрессии. Другие примеры — это экспоненциальная функция потерь или кусочно-линейная, которые используются в методе опорных векторов. \n",
      "Слайд 16\n",
      "Вот графики этих функций. Видно, что они все, действительно, оценивают сверху пороговую функцию потерь. При этом все они делают это по-разному. Какие-то имеют экспоненциальный рост, какие-то более медленный темп роста при уменьшении отступа.\n",
      "\n",
      "Слайд 17\n",
      "Давайте возьмем для примера логистическую функцию потерь и запишем функционал для нее. Он будет выглядеть вот так. Мы усредняем значение данной функции. Этот функционал будет гладким. Чтобы понять, как его оптимизировать, давайте поставим вместо отступа его определение. То есть Yi истинный ответ, умноженный на скалярное произведение вектора весов на вектор признаков Xi. Видно, что мы получили гладкий, хороший функционал, у которого легко посчитать градиенты по вектору весов W и осуществлять градиентный спуск или пользоваться любым другим вашим любимым методом оптимизации. \n",
      "Слайд 18\n",
      "Итак, что мы делаем при решении задачи классификации, при обучении линейного классификатора? Мы оцениваем сверху долю неправильных ответов, наш базовый функционал ошибки, с помощью некоторой гладкой функции потерь, например, логистической. И далее минимизируем эту гладкую функцию потерь с помощью любого метода оптимизации — стохастического градиентного спуска, градиентного спуска или чего-то еще. И при этом надеемся, что минимизации данного функционала будет также приводить к минимизации доли неправильных ответов. Кстати, обратите внимание: в случае с логистической функцией потерь, даже если все отступы стали больше нуля, все равно алгоритм градиентной оптимизации будет стремиться увеличивать отступы, то есть увеличивать уверенность классификатора в этих ответах. Это довольно хорошее свойство.\n",
      "Слайд 19\n",
      "Логистическая регрессия позволяет не только вычислять классификацию для произвольного объекта , но и оценивать апостериорные вероятности его принадлежности классам:\n",
      "с помощью сигмоидальной функции \n"
     ]
    }
   ],
   "source": [
    "print(docx_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066da31a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
